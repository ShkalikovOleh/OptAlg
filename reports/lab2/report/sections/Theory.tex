\begin{center}
    \section*{Теоретична частина}
\end{center}
\SetKwInOut{Parametr}{}

Задача безумовної оптимізації скалярної функції $f(x)$
полягає у тому, щоб знайти такий $x_{min} \in D$
($ D \subseteq \mathbb{R}^n $ - область визначення $f$), що:

\begin{equation} \label{eq:optimization_task}
    x_{min} = \argmin\limits_{x \in D} f(x)
\end{equation}

Не для усіх функцій можливо просто та швидко
аналітично знайти екстремуми, тому у практичних
задачах дуже часто використовуються числені методи
оптимізації. У даній роботі ми розглянемо

\subsection*{Методи спуску}

Для оптимізації скалярної функцій можна
використовувати методи спуску, що на кожному кроці
будуть наближати нас до якогось локального мінімуму.
Їх можна описати наступною процедурої зміни
аргумента функції($\alpha_k > 0$, $k \in \mathbb{N}$):

\begin{equation} \label{eq:descent}
    x_{k+1} = x_{k} - \alpha_k p_{k}
\end{equation}
За умови, що виконується нерівність:
\begin{equation} \label{eq:descent_require}
    f(x_{k+1}) < f(x_k)
\end{equation}

Ітерації спуску продовжуются доки не виконана умова зупинки.
Серед умов зупинки можна виділити наступні($\varepsilon > 0,\;
n \in \mathbb{N}$ - параметри):

\begin{enumerate}
    \item Значення градієнту: $|\nabla f_k| < \varepsilon$
    \item Різниця аргументів: $|x_k - x_{k-1}| < \varepsilon$
    \item Різниця значення функції: $|f(x_k) - f(x_{k-1})| < \varepsilon$
    \item Кількість ітерацій більша або рівна за $n$
\end{enumerate}
Де $ \nabla f_{k} = \nabla f(x_{k})$(надалі будемо
використовувати це позначення).

\subsection*{Метод Ньютона}

Метод Ньютона являє собою методом спуску, що використовує
похідні другого цільової функцій, а саме, напрям спуску
процедури \ref{eq:descent} має вигляд:
\begin{equation}
    p_k = H^{-1}_k \nabla f_k
\end{equation} \label{eq:newton}
,де $H_k$ - матриця Гессе функції $f$ у точці $x_k$.
Такий вибір кроку забезпечує більшу швидкість збіжності у
порівнянні з методами, що використовують лише похідні першого порядку,
бо більш враховують властивості цільової функції.
Отже, маємо алгоритм метода Ньютона.

\begin{algorithm}[H] \label{alg:newton}
    \SetAlgoLined
    \KwIn{$x_0$}
    \KwResult{$x_{min}$}
    $x_1 \leftarrow x_0$\;
    \While{не виконана умова зупинки}
    {
        $\alpha_k \leftarrow \argmin\limits_{\alpha > 0} f(x_{k} - \alpha H^{-1}_k \nabla f_{k})$\;
        $x_{k+1} \leftarrow x_{k} - \alpha_k H^{-1}_k \nabla f_{k}$\;
    }
    \KwOut{$x_k$}
    \caption{Метод Ньютона}
\end{algorithm}

\subsection*{Квазіньютоновські методи}

Метод Ньютона вимагає позитивну визначенність матриці Гессе
цільової функції у точці на кожному кроці. Ця вимога значно обмежує
Кількість функцій, які ми можемо оптимізувати за допомогою
цього методу. Тому, квазіньютоновські методи використовують
у процесі своєї роботи не обернений гессіан(як у \ref{eq:newton}),
а наближенне його значення:
\begin{equation}
    p_k = B_k \nabla f_k
\end{equation}
Існує багато методів обчислення цього наближення $B_k$.
Серед них можна виділити наступні
($y_k = \nabla f_k - \nabla f_{k-1}, \;
\Delta x_k = x_k - x_{k-1} $):
\begin{enumerate}
    \item SR1
    $$ B_k = B_{k-1} + \frac{(\Delta x_{k} - B_{k-1}y_k)
    (\Delta x_{k} - B_{k-1}y_k)^{T}}
    {(\Delta x_{k} - B_{k-1}y_k)^{T}y_k} $$
    \item Broyden
    $$ B_k = B_{k-1} + \frac{(\Delta x_{k} - B_{k-1}y_k)
    \Delta x_{k}^{T}B_{k-1}}
    {\Delta x_{k}^{T}B_{k-1}y_k} $$
    \item DFP
    $$ B_k = B_{k-1} + \frac{\Delta x_{k}\Delta x_{k}^{T}}
    {\Delta x_{k}^{T}y_k} - \frac{B_{k-1}y_ky_k^{T}B_{k-1}}{y_k^{T}B_{k-1}y_k} $$
    \item BFGS
    $$ B_k = \left( I - \frac{\Delta x_{k}y_k^{T}}{y_k^{T}\Delta x_k} \right) B_{k-1}
    \left( I - \frac{y_k \Delta x_{k}^{T}}{y_k^{T}\Delta x_k} \right) +
    \frac{\Delta x_{k}\Delta x_{k}^{T}}{y_k^{T}\Delta x_k}
     $$
\end{enumerate}

Таким чином усі квазіньютоновські алгоритми можна подати у наступному
вигляді.

\begin{algorithm}[H] \label{alg:newton}
    \SetAlgoLined
    \KwIn{$x_0$}
    \KwResult{$x_{min}$}
    $x_1 \leftarrow x_0$\;
    \While{не виконана умова зупинки}
    {
        $\alpha_k \leftarrow \argmin\limits_{\alpha > 0} f(x_{k} - \alpha B_k \nabla f_{k})$\;
        $x_{k+1} \leftarrow x_{k} - \alpha_k B_k \nabla f_{k}$\;
    }
    \KwOut{$x_k$}
    \caption{Квазіньютоновські методи}
\end{algorithm}

\subsection*{Метод Гука-Дживса}

\subsection*{Метод Нелдера-Міда}

\subsection*{Генетичний алгоритм}